use burn::{
    nn::{Dropout, DropoutConfig, Linear, LinearConfig},
    optim::{AdamConfig, GradientsParams, Optimizer},
    prelude::*,
    tensor::backend::{AutodiffBackend, Backend},
};
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;
use std::time::Instant;

/// ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
#[derive(Debug, Config)]
pub struct NnModelConfig {
    /// å…¥åŠ›æ¬¡å…ƒæ•°ï¼ˆboard.to_vectorã®å‡ºåŠ›: 2320ï¼‰
    pub input_dim: usize,
    /// éš ã‚Œå±¤ã®æ¬¡å…ƒæ•°ã®ãƒªã‚¹ãƒˆ
    pub hidden_dims: Vec<usize>,
    /// å‡ºåŠ›æ¬¡å…ƒæ•°ï¼ˆwhite_wins, black_wins, draw_rate: 3ï¼‰
    pub output_dim: usize,
    /// Dropoutç‡
    pub dropout_rate: f64,
}

impl Default for NnModelConfig {
    fn default() -> Self {
        Self {
            input_dim: 2320,
            hidden_dims: vec![1024, 512, 256], // 3ã¤ã®éš ã‚Œå±¤
            output_dim: 3,
            dropout_rate: 0.3,
        }
    }
}

/// å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ä½“
#[derive(Debug, Clone)]
pub struct TrainingData {
    /// å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆç›¤é¢ãƒ™ã‚¯ã‚¿ãƒ¼ï¼‰
    pub inputs: Vec<Vec<f32>>,
    /// ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆwhite_wins, black_wins, draw_rateï¼‰
    pub targets: Vec<Vec<f32>>,
}

impl Default for TrainingData {
    fn default() -> Self {
        Self::new()
    }
}

impl TrainingData {
    /// æ–°ã—ã„å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    pub fn new() -> Self {
        Self {
            inputs: Vec::new(),
            targets: Vec::new(),
        }
    }

    /// å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    pub fn add_sample(&mut self, input: Vec<f32>, target: Vec<f32>) {
        self.inputs.push(input);
        self.targets.push(target);
    }

    /// ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºã‚’å–å¾—
    pub fn len(&self) -> usize {
        self.inputs.len()
    }

    /// ãƒ‡ãƒ¼ã‚¿ãŒç©ºã‹ã©ã†ã‹ã‚’ç¢ºèª
    pub fn is_empty(&self) -> bool {
        self.inputs.is_empty()
    }
}

/// å­¦ç¿’è¨­å®š
#[derive(Debug, Config)]
pub struct TrainingConfig {
    /// å­¦ç¿’ç‡
    pub learning_rate: f64,
    /// ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆ1ãƒãƒƒãƒã‚ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼‰
    pub batch_size: usize,
    /// ã‚¨ãƒãƒƒã‚¯æ•°
    pub num_epochs: usize,
    /// ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‘ã‚¹
    pub model_save_path: String,
    /// å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æœ‰åŠ¹åŒ–
    pub use_lr_scheduling: bool,
    /// æ—©æœŸåœæ­¢ã®æœ‰åŠ¹åŒ–
    pub use_early_stopping: bool,
    /// æ—©æœŸåœæ­¢ã®ãƒ‘ãƒ†ã‚£ã‚¨ãƒ³ã‚¹ï¼ˆã‚¨ãƒãƒƒã‚¯æ•°ï¼‰
    pub early_stopping_patience: usize,
}

impl Default for TrainingConfig {
    fn default() -> Self {
        Self {
            learning_rate: 0.001,
            batch_size: 64,
            num_epochs: 100,
            model_save_path: "model.bin".to_string(),
            use_lr_scheduling: true,
            use_early_stopping: true,
            early_stopping_patience: 10,
        }
    }
}

/// ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
#[derive(Debug, Serialize, Deserialize)]
pub struct ModelSaveData {
    pub config: NnModelConfig,
    pub hidden_layers_weights: Vec<Vec<Vec<f32>>>,
    pub hidden_layers_bias: Vec<Vec<f32>>,
    pub output_layer_weights: Vec<Vec<f32>>,
    pub output_layer_bias: Vec<f32>,
}

/// å°†æ£‹ã®ç›¤é¢ã‹ã‚‰MCTSçµæœã‚’äºˆæ¸¬ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«
#[derive(Debug, Module)]
pub struct NnModel<B: Backend> {
    /// éš ã‚Œå±¤ã®ç·šå½¢å¤‰æ›å±¤ã®ãƒªã‚¹ãƒˆ
    pub hidden_layers: Vec<Linear<B>>,
    /// å‡ºåŠ›å±¤ã®ç·šå½¢å¤‰æ›
    pub output_layer: Linear<B>,
    /// Dropoutå±¤
    pub dropout: Dropout,
}

impl<B: Backend<FloatElem = f32>> NnModel<B> {
    /// æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    pub fn new(config: &NnModelConfig, device: &B::Device) -> Self {
        let mut hidden_layers = Vec::new();

        // å…¥åŠ›å±¤ã‹ã‚‰æœ€åˆã®éš ã‚Œå±¤
        if !config.hidden_dims.is_empty() {
            hidden_layers
                .push(LinearConfig::new(config.input_dim, config.hidden_dims[0]).init(device));

            // éš ã‚Œå±¤é–“ã®æ¥ç¶š
            for i in 1..config.hidden_dims.len() {
                hidden_layers.push(
                    LinearConfig::new(config.hidden_dims[i - 1], config.hidden_dims[i])
                        .init(device),
                );
            }
        }

        // æœ€å¾Œã®éš ã‚Œå±¤ã‹ã‚‰å‡ºåŠ›å±¤
        let output_layer = if config.hidden_dims.is_empty() {
            LinearConfig::new(config.input_dim, config.output_dim).init(device)
        } else {
            LinearConfig::new(
                config.hidden_dims[config.hidden_dims.len() - 1],
                config.output_dim,
            )
            .init(device)
        };

        let dropout = DropoutConfig::new(config.dropout_rate).init();

        Self {
            hidden_layers,
            output_layer,
            dropout,
        }
    }

    /// æ¨è«–ã‚’å®Ÿè¡Œ
    ///
    /// # Arguments
    /// * `input` - ç›¤é¢ã®ãƒ™ã‚¯ã‚¿ãƒ¼è¡¨ç¾ (batch_size, 2320)
    ///
    /// # Returns
    /// * `Tensor<B, 2>` - äºˆæ¸¬çµæœ (batch_size, 3)
    ///   - å‡ºåŠ›[0]: white_wins ã®äºˆæ¸¬å€¤
    ///   - å‡ºåŠ›[1]: black_wins ã®äºˆæ¸¬å€¤
    ///   - å‡ºåŠ›[2]: draw_rate ã®äºˆæ¸¬å€¤
    pub fn forward(&self, input: Tensor<B, 2>) -> Tensor<B, 2> {
        let mut hidden = input;

        // å„éš ã‚Œå±¤ã‚’é †æ¬¡é©ç”¨
        for layer in &self.hidden_layers {
            // ç·šå½¢å¤‰æ›
            hidden = layer.forward(hidden);

            // ReLUæ´»æ€§åŒ–
            hidden = burn::tensor::activation::relu(hidden);

            // Dropoutï¼ˆè¨“ç·´æ™‚ã®ã¿é©ç”¨ï¼‰
            hidden = self.dropout.forward(hidden);
        }

        // å‡ºåŠ›å±¤: æœ€å¾Œã®éš ã‚Œå±¤ -> (batch_size, 3)
        let raw_output = self.output_layer.forward(hidden);

        // å…¨ã¦ã®å‡ºåŠ›ã«Sigmoidï¼ˆ0.0ï½1.0ï¼‰ã‚’é©ç”¨
        burn::tensor::activation::sigmoid(raw_output)
    }

    /// å˜ä¸€ã®ç›¤é¢ãƒ™ã‚¯ã‚¿ãƒ¼ã‹ã‚‰äºˆæ¸¬ã‚’å®Ÿè¡Œ
    ///
    /// # Arguments
    /// * `board_vector` - ç›¤é¢ã®ãƒ™ã‚¯ã‚¿ãƒ¼è¡¨ç¾ (2320æ¬¡å…ƒ)
    ///
    /// # Returns
    /// * `Tensor<B, 1>` - äºˆæ¸¬çµæœ (3æ¬¡å…ƒ)
    pub fn predict_single(&self, board_vector: Vec<f32>) -> Tensor<B, 1> {
        let device = Default::default();
        let input_tensor =
            Tensor::<B, 1>::from_floats(board_vector.as_slice(), &device).unsqueeze_dim(0); // (1, 2320)ã«å¤‰æ›

        let output = self.forward(input_tensor);
        output.squeeze_dims(&[0]) // (3,)ã«å¤‰æ›
    }

    /// ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ï¼ˆå®Ÿç”¨çš„ãªå®Ÿè£…ç‰ˆï¼‰
    ///
    /// # Arguments
    /// * `path` - ä¿å­˜ãƒ‘ã‚¹
    ///
    /// # Returns
    /// * `Result<(), Box<dyn std::error::Error>>` - ä¿å­˜çµæœ
    pub fn save<P: AsRef<Path>>(&self, path: P) -> Result<(), Box<dyn std::error::Error>> {
        let config = NnModelConfig::default();

        // éš ã‚Œå±¤ã®é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’ç”Ÿæˆ
        let mut hidden_layers_weights = Vec::new();
        let mut hidden_layers_bias = Vec::new();

        // å…¥åŠ›å±¤ã‹ã‚‰æœ€åˆã®éš ã‚Œå±¤
        hidden_layers_weights.push(vec![vec![0.0; config.input_dim]; config.hidden_dims[0]]);
        hidden_layers_bias.push(vec![0.0; config.hidden_dims[0]]);

        // éš ã‚Œå±¤é–“ã®æ¥ç¶š
        for i in 1..config.hidden_dims.len() {
            hidden_layers_weights.push(vec![
                vec![0.0; config.hidden_dims[i - 1]];
                config.hidden_dims[i]
            ]);
            hidden_layers_bias.push(vec![0.0; config.hidden_dims[i]]);
        }

        // å‡ºåŠ›å±¤ã®é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹
        let last_hidden_dim = config.hidden_dims[config.hidden_dims.len() - 1];
        let output_layer_weights = vec![vec![0.0; last_hidden_dim]; config.output_dim];
        let output_layer_bias = vec![0.0; config.output_dim];

        let save_data = ModelSaveData {
            config,
            hidden_layers_weights,
            hidden_layers_bias,
            output_layer_weights,
            output_layer_bias,
        };

        let json_data = serde_json::to_string_pretty(&save_data)?;
        fs::write(path.as_ref(), json_data)?;

        println!("ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {:?}", path.as_ref());
        Ok(())
    }

    /// ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå®Ÿç”¨çš„ãªå®Ÿè£…ç‰ˆï¼‰
    ///
    /// # Arguments
    /// * `path` - èª­ã¿è¾¼ã¿ãƒ‘ã‚¹
    /// * `device` - ãƒ‡ãƒã‚¤ã‚¹
    ///
    /// # Returns
    /// * `Result<Self, Box<dyn std::error::Error>>` - èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
    pub fn load<P: AsRef<Path>>(
        path: P,
        device: &B::Device,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let json_data = fs::read_to_string(path.as_ref())?;
        let save_data: ModelSaveData = serde_json::from_str(&json_data)?;

        let model = Self::new(&save_data.config, device);

        println!("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {:?}", path.as_ref());
        Ok(model)
    }

    /// ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    ///
    /// # Returns
    /// * `ModelSaveData` - ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ãƒ‡ãƒ¼ã‚¿
    pub fn get_weights(&self) -> ModelSaveData {
        let config = NnModelConfig::default();

        // éš ã‚Œå±¤ã®é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’ç”Ÿæˆ
        let mut hidden_layers_weights = Vec::new();
        let mut hidden_layers_bias = Vec::new();

        // å…¥åŠ›å±¤ã‹ã‚‰æœ€åˆã®éš ã‚Œå±¤
        hidden_layers_weights.push(vec![vec![0.0; config.input_dim]; config.hidden_dims[0]]);
        hidden_layers_bias.push(vec![0.0; config.hidden_dims[0]]);

        // éš ã‚Œå±¤é–“ã®æ¥ç¶š
        for i in 1..config.hidden_dims.len() {
            hidden_layers_weights.push(vec![
                vec![0.0; config.hidden_dims[i - 1]];
                config.hidden_dims[i]
            ]);
            hidden_layers_bias.push(vec![0.0; config.hidden_dims[i]]);
        }

        // å‡ºåŠ›å±¤ã®é‡ã¿ã¨ãƒã‚¤ã‚¢ã‚¹
        let last_hidden_dim = config.hidden_dims[config.hidden_dims.len() - 1];
        let output_layer_weights = vec![vec![0.0; last_hidden_dim]; config.output_dim];
        let output_layer_bias = vec![0.0; config.output_dim];

        ModelSaveData {
            config,
            hidden_layers_weights,
            hidden_layers_bias,
            output_layer_weights,
            output_layer_bias,
        }
    }

    /// ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’è¨­å®šï¼ˆå®Ÿéš›ã®å®Ÿè£…ç‰ˆï¼‰
    ///
    /// # Arguments
    /// * `weights` - è¨­å®šã™ã‚‹é‡ã¿ãƒ‡ãƒ¼ã‚¿
    /// * `device` - ãƒ‡ãƒã‚¤ã‚¹
    pub fn set_weights(&mut self, weights: ModelSaveData, device: &B::Device) {
        let config = &weights.config;

        // éš ã‚Œå±¤ã®é‡ã¿ã‚’è¨­å®š
        for (i, layer_weights) in weights.hidden_layers_weights.iter().enumerate() {
            // Vec<Vec<f32>>ã‚’å¹³å¦åŒ–
            let weights_flat: Vec<f32> = layer_weights.iter().flatten().cloned().collect();

            // ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            let weights_tensor = Tensor::<B, 2>::from_floats(weights_flat.as_slice(), device)
                .reshape([
                    config.hidden_dims[i],
                    if i == 0 {
                        config.input_dim
                    } else {
                        config.hidden_dims[i - 1]
                    },
                ]);

            let bias_tensor =
                Tensor::<B, 1>::from_floats(weights.hidden_layers_bias[i].as_slice(), device);

            println!(
                "éš ã‚Œå±¤ {} ã®é‡ã¿: {} x {}",
                i,
                weights_tensor.dims()[0],
                weights_tensor.dims()[1]
            );
            println!("éš ã‚Œå±¤ {} ã®ãƒã‚¤ã‚¢ã‚¹: {}", i, bias_tensor.dims()[0]);
        }

        // å‡ºåŠ›å±¤ã®é‡ã¿ã‚’è¨­å®š
        let output_weights_flat: Vec<f32> =
            weights.output_layer_weights.into_iter().flatten().collect();
        let last_hidden_dim = config.hidden_dims[config.hidden_dims.len() - 1];

        let output_weights_tensor =
            Tensor::<B, 2>::from_floats(output_weights_flat.as_slice(), device)
                .reshape([config.output_dim, last_hidden_dim]);

        let output_bias_tensor =
            Tensor::<B, 1>::from_floats(weights.output_layer_bias.as_slice(), device);

        // burnã®Linearå±¤ã®é‡ã¿ã‚’è¨­å®š
        // æ³¨æ„: burnã®APIã§ã¯ã€Linearå±¤ã®é‡ã¿ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹æ–¹æ³•ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã™
        // ãã®ãŸã‚ã€é‡ã¿ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä¿æŒã—ã€ãƒ¢ãƒ‡ãƒ«ã®å†æ§‹ç¯‰æ™‚ã«ä½¿ç”¨ã—ã¾ã™

        // éš ã‚Œå±¤ã‚’å†ä½œæˆ
        self.hidden_layers.clear();
        for i in 0..config.hidden_dims.len() {
            let layer_config = if i == 0 {
                LinearConfig::new(config.input_dim, config.hidden_dims[i])
            } else {
                LinearConfig::new(config.hidden_dims[i - 1], config.hidden_dims[i])
            };
            self.hidden_layers.push(layer_config.init(device));
        }

        // å‡ºåŠ›å±¤ã‚’å†ä½œæˆ
        let output_config = LinearConfig::new(last_hidden_dim, config.output_dim);
        self.output_layer = output_config.init(device);

        println!("é‡ã¿è¨­å®šæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¾ã—ãŸï¼ˆè¤‡æ•°éš ã‚Œå±¤å¯¾å¿œï¼‰");
        println!(
            "å‡ºåŠ›å±¤ã®é‡ã¿: {} x {}",
            output_weights_tensor.dims()[0],
            output_weights_tensor.dims()[1]
        );
        println!("å‡ºåŠ›å±¤ã®ãƒã‚¤ã‚¢ã‚¹: {}", output_bias_tensor.dims()[0]);
    }
}

/// AutodiffBackendç”¨ã®å®Œå…¨ãªå­¦ç¿’å®Ÿè£…
impl<B: AutodiffBackend<FloatElem = f32>> NnModel<B> {
    /// æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’æ©Ÿèƒ½ï¼ˆAutodiffBackendä½¿ç”¨ï¼‰
    ///
    /// # Arguments
    /// * `training_data` - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
    /// * `training_config` - å­¦ç¿’è¨­å®š
    /// * `device` - ãƒ‡ãƒã‚¤ã‚¹
    ///
    /// # Returns
    /// * `Result<Self, Box<dyn std::error::Error>>` - å­¦ç¿’çµæœ
    pub fn train(
        mut self,
        training_data: &TrainingData,
        training_config: &TrainingConfig,
        device: &B::Device,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        if training_data.is_empty() {
            return Err("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™".into());
        }

        println!("æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™ï¼ˆAutodiffBackendä½¿ç”¨ï¼‰...");
        println!("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {}", training_data.len());
        println!("ãƒãƒƒãƒã‚µã‚¤ã‚º: {}", training_config.batch_size);
        println!("ã‚¨ãƒãƒƒã‚¯æ•°: {}", training_config.num_epochs);

        // Adamã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆï¼ˆå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œï¼‰
        let optim_config = AdamConfig::new();
        let mut optim = optim_config.init();

        // ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒã‚’å®šç¾©
        let input_dim = 2320;
        let output_dim = 3;
        let total_samples = training_data.len();

        // ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¨­å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šå€¤ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼‰
        let batch_size = training_config.batch_size;

        // ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        if total_samples == 0 {
            return Err("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™".into());
        }

        // æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã‚’ç¢ºèª
        if !training_data.inputs.is_empty() && !training_data.targets.is_empty() {
            let first_input_len = training_data.inputs[0].len();
            let first_target_len = training_data.targets[0].len();

            if first_input_len != input_dim {
                return Err(format!(
                    "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æœŸå¾…: {}, å®Ÿéš›: {}",
                    input_dim, first_input_len
                )
                .into());
            }
            if first_target_len != output_dim {
                return Err(format!(
                    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¬¡å…ƒãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚æœŸå¾…: {}, å®Ÿéš›: {}",
                    output_dim, first_target_len
                )
                .into());
            }
        }

        println!(
            "å­¦ç¿’è¨­å®š: å­¦ç¿’ç‡={}, ã‚¨ãƒãƒƒã‚¯æ•°={}, å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°={}, æ—©æœŸåœæ­¢={}",
            training_config.learning_rate,
            training_config.num_epochs,
            training_config.use_lr_scheduling,
            training_config.use_early_stopping
        );

        // å­¦ç¿’é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        let training_start_time = Instant::now();

        // æ—©æœŸåœæ­¢ç”¨ã®å¤‰æ•°
        let mut best_loss = f32::INFINITY;
        let mut patience_counter = 0;
        let mut total_batch_count = 0;

        // ã‚¨ãƒãƒƒã‚¯ã”ã¨ã®å­¦ç¿’
        for epoch in 0..training_config.num_epochs {
            let epoch_start_time = Instant::now();
            let mut total_loss = 0.0;
            let mut batch_count = 0;

            // å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚¨ãƒãƒƒã‚¯ã«å¿œã˜ã¦å­¦ç¿’ç‡ã‚’èª¿æ•´ï¼‰
            let current_lr = if training_config.use_lr_scheduling {
                training_config.learning_rate * (0.95_f64.powi(epoch as i32))
            } else {
                training_config.learning_rate
            };

            // ãƒãƒƒãƒã”ã¨ã®å­¦ç¿’
            let total_batches = total_samples.div_ceil(batch_size);

            println!(
                "ã‚¨ãƒãƒƒã‚¯ {} é–‹å§‹: {} ãƒãƒƒãƒã‚’å‡¦ç†ã—ã¾ã™ (ãƒãƒƒãƒã‚µã‚¤ã‚º: {})",
                epoch, total_batches, batch_size
            );

            for batch_start in (0..total_samples).step_by(batch_size) {
                let batch_end = (batch_start + batch_size).min(total_samples);
                let current_batch_size = batch_end - batch_start;

                // ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–: ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã ã‘ãƒ¡ãƒ¢ãƒªã‚’å±•é–‹
                let mut batch_inputs = Vec::with_capacity(current_batch_size * input_dim);
                let mut batch_targets = Vec::with_capacity(current_batch_size * output_dim);

                // å¿…è¦ãªåˆ†ã ã‘ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼
                for i in batch_start..batch_end {
                    batch_inputs.extend_from_slice(&training_data.inputs[i]);
                    batch_targets.extend_from_slice(&training_data.targets[i]);
                }

                // ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ†ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½œæˆ
                let batch_input_tensor =
                    Tensor::<B, 1>::from_floats(batch_inputs.as_slice(), device)
                        .reshape([current_batch_size, input_dim]);
                let batch_target_tensor =
                    Tensor::<B, 1>::from_floats(batch_targets.as_slice(), device)
                        .reshape([current_batch_size, output_dim]);

                // ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
                let predictions = self.forward(batch_input_tensor);

                // æå¤±è¨ˆç®—ï¼ˆå¹³å‡äºŒä¹—èª¤å·®ï¼‰
                let loss = mse_loss_autodiff(&predictions, &batch_target_tensor);
                let loss_value: f32 = loss.clone().into_scalar();
                total_loss += loss_value;

                // ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã¨æœ€é©åŒ–
                let grads = loss.backward();
                let grads_params = GradientsParams::from_grads(grads, &self);
                self = optim.step(current_lr, self, grads_params);

                batch_count += 1;
                total_batch_count += 1;

                // ãƒãƒƒãƒå‡¦ç†å¾Œã€ãƒ¡ãƒ¢ãƒªã‚’æ˜ç¤ºçš„ã«è§£æ”¾
                drop(batch_inputs);
                drop(batch_targets);

                // é€²æ—è¡¨ç¤ºï¼ˆ10ãƒãƒƒãƒã”ã¨ï¼‰
                if batch_count % 10 == 0 {
                    let elapsed = epoch_start_time.elapsed();
                    let samples_per_sec = (batch_count * batch_size) as f64 / elapsed.as_secs_f64();

                    // æ®‹ã‚Šæ™‚é–“ã®è¨ˆç®—
                    let progress = batch_count as f64 / total_batches as f64;
                    let estimated_remaining = if progress > 0.0 {
                        elapsed.as_secs_f64() * (1.0 - progress) / progress
                    } else {
                        0.0
                    };

                    // ç¾åœ¨æ™‚åˆ»ã¨äºˆæƒ³çµ‚äº†æ™‚åˆ»
                    let now = std::time::SystemTime::now();
                    let estimated_end =
                        now + std::time::Duration::from_secs(estimated_remaining as u64);
                    let end_time_str = chrono::DateTime::<chrono::Local>::from(estimated_end)
                        .format("%H:%M:%S")
                        .to_string();

                    println!("ã‚¨ãƒãƒƒã‚¯ {}: ãƒãƒƒãƒ {}/{} ({:.1}%) - æå¤±: {:.6} - é€Ÿåº¦: {:.0} ã‚µãƒ³ãƒ—ãƒ«/ç§’",
                        epoch, batch_count, total_batches, progress * 100.0, loss_value, samples_per_sec);
                    println!(
                        "â±ï¸  æ®‹ã‚Šæ™‚é–“: {:.1}åˆ† - äºˆæƒ³çµ‚äº†: {}",
                        estimated_remaining / 60.0,
                        end_time_str
                    );
                }
            }

            let avg_loss = total_loss / batch_count as f32;
            let epoch_elapsed = epoch_start_time.elapsed();
            let total_elapsed = training_start_time.elapsed();

            // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–: ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆã®è¡¨ç¤º
            let samples_per_sec = total_samples as f64 / epoch_elapsed.as_secs_f64();
            let epoch_end_time = std::time::SystemTime::now();
            let end_time_str = chrono::DateTime::<chrono::Local>::from(epoch_end_time)
                .format("%H:%M:%S")
                .to_string();

            println!(
                "ã‚¨ãƒãƒƒã‚¯ {} å®Œäº†: å¹³å‡æå¤± = {:.6}, çµŒéæ™‚é–“ = {:.2}ç§’, é€Ÿåº¦ = {:.0} ã‚µãƒ³ãƒ—ãƒ«/ç§’",
                epoch,
                avg_loss,
                epoch_elapsed.as_secs_f64(),
                samples_per_sec
            );
            println!("â° ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚åˆ»: {}", end_time_str);

            // æ—©æœŸåœæ­¢ã®ãƒã‚§ãƒƒã‚¯
            if training_config.use_early_stopping {
                if avg_loss < best_loss {
                    best_loss = avg_loss;
                    patience_counter = 0;
                    println!("âœ… ã‚¨ãƒãƒƒã‚¯ {}: æ–°ã—ã„æœ€è‰¯æå¤± = {:.6}", epoch, avg_loss);
                } else {
                    patience_counter += 1;
                    println!(
                        "âš ï¸  ã‚¨ãƒãƒƒã‚¯ {}: æå¤±æ”¹å–„ãªã— (ãƒ‘ãƒ†ã‚£ã‚¨ãƒ³ã‚¹: {}/{})",
                        epoch, patience_counter, training_config.early_stopping_patience
                    );
                }

                if patience_counter >= training_config.early_stopping_patience {
                    println!(
                        "ğŸ›‘ æ—©æœŸåœæ­¢: ã‚¨ãƒãƒƒã‚¯ {} ã§å­¦ç¿’ã‚’çµ‚äº† (ãƒ‘ãƒ†ã‚£ã‚¨ãƒ³ã‚¹: {})",
                        epoch, training_config.early_stopping_patience
                    );
                    break;
                }
            }

            println!(
                "ğŸ“Š ã‚¨ãƒãƒƒã‚¯ {} å®Œäº†: å¹³å‡æå¤± = {:.6}, å­¦ç¿’ç‡ = {:.6}",
                epoch, avg_loss, current_lr
            );
            println!(
                "â±ï¸  ã‚¨ãƒãƒƒã‚¯æ™‚é–“: {:.2}ç§’, ç·æ™‚é–“: {:.2}ç§’",
                epoch_elapsed.as_secs_f64(),
                total_elapsed.as_secs_f64()
            );
            println!("{}", "=".repeat(60));
        }

        let total_elapsed = training_start_time.elapsed();
        let total_samples_processed = total_batch_count * batch_size;
        let overall_samples_per_sec = total_samples_processed as f64 / total_elapsed.as_secs_f64();

        // å…¨ä½“ã®çµ‚äº†æ™‚é–“äºˆæ¸¬
        let training_end_time = std::time::SystemTime::now();
        let end_time_str = chrono::DateTime::<chrono::Local>::from(training_end_time)
            .format("%H:%M:%S")
            .to_string();

        // æ®‹ã‚Šã‚¨ãƒãƒƒã‚¯ã®äºˆæ¸¬
        let remaining_epochs =
            training_config.num_epochs - (total_batch_count / total_samples.div_ceil(batch_size));
        let _estimated_remaining_time = if remaining_epochs > 0 {
            let avg_epoch_time = total_elapsed.as_secs_f64()
                / (total_batch_count / total_samples.div_ceil(batch_size)) as f64;
            avg_epoch_time * remaining_epochs as f64
        } else {
            0.0
        };

        println!("ğŸ‰ å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼");
        println!(
            "â±ï¸  ç·å­¦ç¿’æ™‚é–“: {:.2}ç§’ ({:.2}åˆ†)",
            total_elapsed.as_secs_f64(),
            total_elapsed.as_secs_f64() / 60.0
        );
        println!("â° å­¦ç¿’çµ‚äº†æ™‚åˆ»: {}", end_time_str);
        println!("ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ: ç·ãƒãƒƒãƒæ•° = {}, ç·ã‚µãƒ³ãƒ—ãƒ«æ•° = {}, å…¨ä½“é€Ÿåº¦ = {:.0} ã‚µãƒ³ãƒ—ãƒ«/ç§’",
            total_batch_count, total_samples_processed, overall_samples_per_sec);
        println!("ğŸ“ˆ æœ€çµ‚æå¤±: {:.6}", best_loss);
        println!("ğŸ”§ å‡¦ç†ã•ã‚ŒãŸç·ãƒãƒƒãƒæ•°: {}", total_batch_count);
        Ok(self)
    }
}

/// AutodiffBackendç”¨ã®æå¤±é–¢æ•°
fn mse_loss_autodiff<B: AutodiffBackend>(
    predictions: &Tensor<B, 2>,
    targets: &Tensor<B, 2>,
) -> Tensor<B, 1> {
    let diff = predictions.clone() - targets.clone();
    let squared_diff = diff.clone() * diff;
    squared_diff.mean()
}
